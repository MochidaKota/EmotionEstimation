{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def culc_integrate_upper_limit(run_name_list, target_emo, epoch=None):\n",
    "    root_dir = \"/mnt/iot-qnap3/mochida/medical-care/emotionestimation/reports/PIMD_A\"\n",
    "    preds = pd.DataFrame()\n",
    "    \n",
    "    for i, run_name in enumerate(run_name_list):\n",
    "        if glob.glob(f\"{root_dir}/{run_name}/epoch{epoch[i]}/*_pred_all.csv\"):\n",
    "            filepath = glob.glob(f\"{root_dir}/{run_name}/epoch{epoch[i]}/*_pred_all.csv\")[0]\n",
    "            _pred = pd.read_csv(filepath)\n",
    "        else:\n",
    "            raise RuntimeError(f\"{run_name} is not found\")\n",
    "        \n",
    "        if i == 0:\n",
    "            preds['img_path'] = _pred['img_path']\n",
    "            preds['emo_gt'] = _pred['emo_gt']\n",
    "            \n",
    "        preds[f'{run_name}_emo_pred'] = _pred['emo_pred']\n",
    "        preds[f'{run_name}_emo_pos'] = _pred['emo_pos']\n",
    "        \n",
    "    # extract column if column name has 'emo_pred'\n",
    "    gt_and_pred = pd.DataFrame()\n",
    "    gt_list = preds['emo_gt'].copy()\n",
    "    if target_emo == 'comfort':\n",
    "        gt_list = gt_list.replace(2, 0)\n",
    "    elif target_emo == 'discomfort':\n",
    "        gt_list = gt_list.replace(1, 0)\n",
    "        gt_list = gt_list.replace(2, 1)\n",
    "        \n",
    "    gt_and_pred['emo_gt'] = gt_list\n",
    "    gt_and_pred = gt_and_pred.join(preds.filter(like='emo_pred'))\n",
    "    gt_and_pred['upper_limit'] = [0] * len(gt_and_pred)\n",
    "    \n",
    "    #gt_and_pred.iloc[i, 1:]の中で1つでもgt_and_pred[\"emo_gt\"]と一致するものがあればgt_and_pred[\"upper_limit_emo_pred\"] = gt_and_pred[\"emo_gt\"]とする\n",
    "    for i in range(len(gt_and_pred)):\n",
    "        for j in range(1, len(gt_and_pred.columns)):\n",
    "            if gt_and_pred.iloc[i, j] == gt_and_pred[\"emo_gt\"][i]:\n",
    "                gt_and_pred['upper_limit'][i] = gt_and_pred[\"emo_gt\"][i]\n",
    "                break\n",
    "            else:\n",
    "                gt_and_pred['upper_limit'][i] = gt_and_pred.iloc[i, 1:].max()\n",
    "                \n",
    "    # calculate metrics\n",
    "    print(classification_report(gt_and_pred['emo_gt'], gt_and_pred['upper_limit']))\n",
    "    \n",
    "    print(f\"roc_auc_score: {roc_auc_score(gt_and_pred['emo_gt'], gt_and_pred['upper_limit'])}\")\n",
    "    pre, rec, _ = precision_recall_curve(gt_and_pred['emo_gt'], gt_and_pred['upper_limit'])\n",
    "    print(f\"pr_auc_score: {auc(rec, pre)}\")\n",
    "        \n",
    "    return gt_and_pred     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       308\n",
      "           1       0.98      0.92      0.95       308\n",
      "\n",
      "    accuracy                           0.95       616\n",
      "   macro avg       0.95      0.95      0.95       616\n",
      "weighted avg       0.95      0.95      0.95       616\n",
      "\n",
      "roc_auc_score: 0.952922077922078\n",
      "pr_auc_score: 0.9718689614883386\n"
     ]
    }
   ],
   "source": [
    "dis_run_name_list = ['4_d_a', '4_d_g', '4_d_h']\n",
    "\n",
    "p = culc_integrate_upper_limit(dis_run_name_list, 'discomfort', epoch=[10, 10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       775\n",
      "           1       1.00      0.96      0.98       717\n",
      "\n",
      "    accuracy                           0.98      1492\n",
      "   macro avg       0.98      0.98      0.98      1492\n",
      "weighted avg       0.98      0.98      0.98      1492\n",
      "\n",
      "roc_auc_score: 0.9790794979079498\n",
      "pr_auc_score: 0.9891331172108988\n"
     ]
    }
   ],
   "source": [
    "com_run_name_list = ['4_c_a', '4_c_g', '4_c_h']\n",
    "\n",
    "p = culc_integrate_upper_limit(com_run_name_list, 'comfort', epoch=[10, 10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def culc_integrate_average(run_name_list, target_emo, threshold=0.5):\n",
    "    root_dir = \"/mnt/iot-qnap3/mochida/medical-care/emotionestimation/reports/PIMD_A\"\n",
    "    preds = pd.DataFrame()\n",
    "    \n",
    "    for i, run_name in enumerate(run_name_list):\n",
    "        if glob.glob(f\"{root_dir}/{run_name}/*_pred_all.csv\"):\n",
    "            filepath = glob.glob(f\"{root_dir}/{run_name}/*_pred_all.csv\")[0]\n",
    "            _pred = pd.read_csv(filepath)\n",
    "        else:\n",
    "            raise RuntimeError(f\"{run_name} is not found\")\n",
    "        \n",
    "        if i == 0:\n",
    "            preds['img_path'] = _pred['img_path']\n",
    "            preds['emo_gt'] = _pred['emo_gt']\n",
    "            \n",
    "        preds[f'{run_name}_emo_pred'] = _pred['emo_pred']\n",
    "        preds[f'{run_name}_emo_pos'] = _pred['emo_pos']\n",
    "        \n",
    "    # extract column if column name has 'emo_pos' and calculate average, if average is over threshold, emo_pred is 1\n",
    "    gt_and_pred = pd.DataFrame()\n",
    "    gt_list = preds['emo_gt'].copy()\n",
    "    if target_emo == 'comfort':\n",
    "        gt_list = gt_list.replace(2, 0)\n",
    "    elif target_emo == 'discomfort':\n",
    "        gt_list = gt_list.replace(1, 0)\n",
    "        gt_list = gt_list.replace(2, 1)\n",
    "        \n",
    "    gt_and_pred['emo_gt'] = gt_list\n",
    "    gt_and_pred = gt_and_pred.join(preds.filter(like='emo_pos'))\n",
    "    gt_and_pred['average_emo_pos'] = gt_and_pred.iloc[:, 1:].mean(axis=1)\n",
    "    gt_and_pred['average_emo_pred'] = gt_and_pred['average_emo_pos'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "    \n",
    "    # calculate metrics\n",
    "    print(classification_report(gt_and_pred['emo_gt'], gt_and_pred['average_emo_pred']))\n",
    "    print(f\"roc_auc_score: {roc_auc_score(gt_and_pred['emo_gt'], gt_and_pred['average_emo_pred'])}\")\n",
    "    pre, rec, _ = precision_recall_curve(gt_and_pred['emo_gt'], gt_and_pred['average_emo_pred'])\n",
    "    print(f\"pr_auc_score: {auc(rec, pre)}\")\n",
    "    \n",
    "    return gt_and_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
