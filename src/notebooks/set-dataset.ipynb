{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detaset(label_df, target_emo, negative_threshold=0.5, adjust_samples=None):\n",
    "    \n",
    "    '''\n",
    "    主にCVのためのデータセットを作成する関数\n",
    "    1. target_emoに応じて、target_videosとnon_target_videosを決定する\n",
    "    2. target_videoからpositive_samplesを抽出する\n",
    "    3. non_target_videoからnegative_samplesを抽出する\n",
    "    4. target_videoからnegative_samplesを抽出する\n",
    "    5. others_videoからnegative_samplesを抽出する\n",
    "    上記の処理をpositive_samplesとnegative_samplesの数が同じになるように行う\n",
    "    \n",
    "    Args\n",
    "    ----------\n",
    "    label_df : DataFrame\n",
    "        ラベルデータ\n",
    "    target_emo : str\n",
    "        positive_samplesを抽出するためのemotion(comfort or discomfort)\n",
    "    negative_threshold : float\n",
    "        negative_samples内のnon_target_labelの割合を調整するためのthreshold。0.5の場合は、negative_samples内のnon_target_labelの割合が50%を超えない。\n",
    "    adjust_samples : tuple(str, int)\n",
    "        作成したデータセットのpositive_samplesとnegative_samplesの数を調整するための引数。第一引数には、調整するvideo_nameを指定する。第二引数には、調整後のサンプル数を指定する。\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : DataFrame\n",
    "        作成したデータセット\n",
    "    video_name_list : DataFrame\n",
    "        作成したデータセットに含まれるvideoの名前のリスト\n",
    "    '''\n",
    "     \n",
    "    label_df['video_name'], _ = zip(*label_df['img_path'].map(util.get_video_name_and_frame_num))\n",
    "    video_df_list = {}\n",
    "    for i in range(1, 26):\n",
    "        video_df_list['video{}'.format(i)] = label_df[label_df['video_name'] == 'video{}'.format(i)]\n",
    "        video_df_list['video{}'.format(i)] = video_df_list['video{}'.format(i)].reset_index(drop=True)\n",
    "    \n",
    "    #! window_sizeに応じて、使用するvideoの変更が必要\n",
    "    # comfort_videos = ['video3', 'video9', 'video12', 'video13', 'video8', 'video15', 'video16', 'video17', 'video10', 'video14', 'video11']\n",
    "    # discomfort_videos = ['video18', 'video19', 'video20', 'video21', 'video22', 'video23', 'video24', 'video25']\n",
    "    # others_videos = ['video1', 'video2', 'video4', 'video5', 'video6', 'video7']\n",
    "     \n",
    "    comfort_videos = []\n",
    "    discomfort_videos = ['video18', 'video19', 'video20', 'video21', 'video22', 'video23', 'video24']\n",
    "    others_videos = ['video1', 'video2', 'video4', 'video5', 'video6', 'video7', 'video3', 'video9', 'video12', 'video13', 'video8', 'video15', 'video16', 'video10', 'video11']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    use_video_list = []\n",
    "    target_videos = None\n",
    "    non_target_videos = None\n",
    "    target_label = 0\n",
    "    not_target_label = 0\n",
    "    \n",
    "    if target_emo == 'comfort':\n",
    "        target_videos = comfort_videos\n",
    "        non_target_videos = discomfort_videos\n",
    "        target_label = 1\n",
    "        not_target_label = 2\n",
    "    elif target_emo == 'discomfort':\n",
    "        target_videos = discomfort_videos\n",
    "        non_target_videos = comfort_videos\n",
    "        target_label = 2\n",
    "        not_target_label = 1\n",
    "        \n",
    "    for video_name in target_videos:\n",
    "        \n",
    "        _df = pd.DataFrame()\n",
    "        use_videos = [video_name]\n",
    "        pos_num = 0\n",
    "        neg_num = 0\n",
    "        non_target_flag = False\n",
    "        \n",
    "        # extract positive samples\n",
    "        target_df = video_df_list[video_name][video_df_list[video_name]['emotion'] == target_label]\n",
    "        pos_num += len(target_df)\n",
    "        print(f'target: {video_name}, len: {len(target_df)}')\n",
    "        \n",
    "        # extract negative samples\n",
    "        if non_target_videos:\n",
    "            non_target_flag = True\n",
    "            non_target_video_name = non_target_videos.pop()\n",
    "            use_videos.append(non_target_video_name)\n",
    "            non_target_df = video_df_list[non_target_video_name][video_df_list[non_target_video_name]['emotion'] == not_target_label]\n",
    "            if len(non_target_df) > int(pos_num * negative_threshold):\n",
    "                if adjust_samples and adjust_samples[0] == non_target_video_name:\n",
    "                    non_target_df = non_target_df.sample(adjust_samples[1], random_state=0)\n",
    "                else:\n",
    "                    non_target_df = non_target_df.sample(int(pos_num * negative_threshold), random_state=0)\n",
    "            neg_num += len(non_target_df)\n",
    "            print(f'non_target: {non_target_video_name}, len: {len(non_target_df)}')\n",
    "        \n",
    "        # others_df = video_df_list[video_name][video_df_list[video_name]['emotion'] == 0]\n",
    "        # if len(others_df) > pos_num - neg_num:\n",
    "        #     others_df = others_df.sample(pos_num - neg_num, random_state=0)\n",
    "        # neg_num += len(others_df)\n",
    "        # print(f'others: {video_name}, len: {len(others_df)}')\n",
    "        \n",
    "        if non_target_flag:\n",
    "            _df = pd.concat([target_df, non_target_df])\n",
    "        else:\n",
    "            _df = pd.concat([target_df])\n",
    "        \n",
    "        while neg_num < pos_num:\n",
    "            if others_videos:\n",
    "                add_others_video_name = others_videos.pop()\n",
    "                use_videos.append(add_others_video_name)\n",
    "                add_others_df = video_df_list[add_others_video_name][video_df_list[add_others_video_name]['emotion'] == 0]\n",
    "                if len(add_others_df) > pos_num - neg_num:\n",
    "                    add_others_df = add_others_df.sample(pos_num - neg_num, random_state=0)\n",
    "                neg_num += len(add_others_df)\n",
    "                print(f'others: {add_others_video_name}, len: {len(add_others_df)}')\n",
    "                _df = pd.concat([_df, add_others_df])\n",
    "            \n",
    "            else:\n",
    "                print('others_videos is empty')\n",
    "                break\n",
    "\n",
    "        print(f'pos_num: {pos_num}, neg_num: {neg_num}')\n",
    "        print()\n",
    "        \n",
    "        df = pd.concat([df, _df])\n",
    "        use_video_list.append(use_videos)\n",
    "    \n",
    "    df = df.sort_values('img_path')   \n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    _use_video_list = [item for sublist in use_video_list for item in sublist]\n",
    "    _use_video_list = list(set(_use_video_list))\n",
    "    _use_video_list.sort()\n",
    "    \n",
    "    video_name_list = pd.DataFrame(columns=_use_video_list)\n",
    "    for i in range(len(use_video_list)):\n",
    "        video_name_list.loc[i, use_video_list[i]] = 1\n",
    "    video_name_list = video_name_list.fillna(0)\n",
    "    video_name_list = video_name_list.astype(int)      \n",
    "            \n",
    "    return df, video_name_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/drop_discomfort_hardnegative_seq_labels(video1-25)_ver2-gazesign_wsize90-ssize3-th5e-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: video18, len: 7\n",
      "others: video11, len: 7\n",
      "pos_num: 7, neg_num: 7\n",
      "\n",
      "target: video19, len: 451\n",
      "others: video10, len: 309\n",
      "others: video16, len: 142\n",
      "pos_num: 451, neg_num: 451\n",
      "\n",
      "target: video20, len: 152\n",
      "others: video15, len: 152\n",
      "pos_num: 152, neg_num: 152\n",
      "\n",
      "target: video21, len: 384\n",
      "others: video8, len: 286\n",
      "others: video13, len: 98\n",
      "pos_num: 384, neg_num: 384\n",
      "\n",
      "target: video22, len: 68\n",
      "others: video12, len: 33\n",
      "others: video9, len: 35\n",
      "pos_num: 68, neg_num: 68\n",
      "\n",
      "target: video23, len: 4\n",
      "others: video3, len: 4\n",
      "pos_num: 4, neg_num: 4\n",
      "\n",
      "target: video24, len: 7\n",
      "others: video7, len: 7\n",
      "pos_num: 7, neg_num: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df, video_name_list = get_detaset(label_df, 'discomfort', negative_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ファイル名の変更忘れずに\n",
    "df.to_csv('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/discomfort-gazesign_labels_wsize90-ssize3.csv', index=False)\n",
    "video_name_list.to_csv('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/discomfort-gazesign_video_name_list_wsize90-ssize3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
