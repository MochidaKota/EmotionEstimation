{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from utils import util\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaze(video_name, r=90):\n",
    "    df = pd.read_csv('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/emo_and_au-gaze-hp(video1-25).csv')\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    df['video_name'], df['frame_num'] = zip(*df['img_path'].map(util.get_video_name_and_frame_num))\n",
    "    video_df = df[df['video_name'] == video_name]\n",
    "    video_df = video_df.reset_index(drop=True)\n",
    "    video_df = video_df.sort_values('frame_num')\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['gaze_pitch'], mode='lines', name='gaze_pitch'))\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['gaze_yaw'], mode='lines', name='gaze_yaw'))\n",
    "    \n",
    "    emo = 0\n",
    "    for i in video_df['frame_num']:\n",
    "        _emo = video_df[video_df['frame_num'] == i]['emotion'].values[0]\n",
    "        if emo != _emo:\n",
    "            # write vertical line\n",
    "            if _emo == 0:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-r, r], mode='lines', line=dict(color='blue', width=1, dash='dash'), showlegend=False))\n",
    "            elif _emo == 1:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-r, r], mode='lines', line=dict(color='red', width=1, dash='dash'), showlegend=False))\n",
    "            elif _emo == 2:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-r, r], mode='lines', line=dict(color='green', width=1, dash='dash'), showlegend=False))\n",
    "        emo = _emo\n",
    "    \n",
    "    fig.update_yaxes(range=[-r, r], title_text='degree')\n",
    "    fig.update_xaxes(title_text='frame id')\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=30, b=0),\n",
    "        legend=dict(orientation='h')\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hp(video_name, range=90):\n",
    "    df = pd.read_csv('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/emo_and_au-gaze-hp(video1-25).csv')\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    df['video_name'], df['frame_num'] = zip(*df['img_path'].map(util.get_video_name_and_frame_num))\n",
    "    video_df = df[df['video_name'] == video_name]\n",
    "    video_df = video_df.reset_index(drop=True)\n",
    "    video_df = video_df.sort_values('frame_num')\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_pitch'], mode='lines', name='headpose_pitch'))\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_roll'], mode='lines', name='headpose_roll'))\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_yaw'], mode='lines', name='headpose_yaw'))\n",
    "\n",
    "    emo = 0\n",
    "    for i in video_df['frame_num']:\n",
    "        _emo = video_df[video_df['frame_num'] == i]['emotion'].values[0]\n",
    "        if emo != _emo:\n",
    "            # write vertical line\n",
    "            if _emo == 0:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-range, range], mode='lines', line=dict(color='blue', width=1, dash='dash'), showlegend=False))\n",
    "            elif _emo == 1:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-range, range], mode='lines', line=dict(color='red', width=1, dash='dash'), showlegend=False))\n",
    "            elif _emo == 2:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-range, range], mode='lines', line=dict(color='green', width=1, dash='dash'), showlegend=False))\n",
    "        emo = _emo\n",
    "    \n",
    "    fig.update_yaxes(range=[-range, range], title_text='degree')\n",
    "    fig.update_xaxes(title_text='frame id')\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=30, b=0),\n",
    "        legend=dict(orientation='h')\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta(video_name, attribute, shift=1):\n",
    "    df = pd.read_csv('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/emo_and_au-gaze-hp(video1-25).csv')\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    df['video_name'], df['frame_num'] = zip(*df['img_path'].map(util.get_video_name_and_frame_num))\n",
    "    video_df = df[df['video_name'] == video_name]\n",
    "    video_df = video_df.reset_index(drop=True)\n",
    "    video_df = video_df.sort_values('frame_num')\n",
    "    video_df['delta_gaze_pitch'] = [0]*len(video_df)\n",
    "    video_df['delta_gaze_yaw'] = [0]*len(video_df)\n",
    "    video_df['delta_hp_pitch'] = [0]*len(video_df)\n",
    "    video_df['delta_hp_roll'] = [0]*len(video_df)\n",
    "    video_df['delta_hp_yaw'] = [0]*len(video_df)\n",
    "    \n",
    "    for i in range(shift, len(video_df)):\n",
    "        video_df.loc[i, 'delta_gaze_pitch'] = video_df.loc[i, 'gaze_pitch'] - video_df.loc[i-shift, 'gaze_pitch']\n",
    "        video_df.loc[i, 'delta_gaze_yaw'] = video_df.loc[i, 'gaze_yaw'] - video_df.loc[i-shift, 'gaze_yaw']\n",
    "        video_df.loc[i, 'delta_hp_pitch'] = video_df.loc[i, 'hp_pitch'] - video_df.loc[i-shift, 'hp_pitch']\n",
    "        video_df.loc[i, 'delta_hp_roll'] = video_df.loc[i, 'hp_roll'] - video_df.loc[i-shift, 'hp_roll']\n",
    "        video_df.loc[i, 'delta_hp_yaw'] = video_df.loc[i, 'hp_yaw'] - video_df.loc[i-shift, 'hp_yaw']\n",
    "        \n",
    "    if attribute == 'gaze':\n",
    "        fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_gaze_pitch'], mode='markers', name='delta_gaze_pitch'))\n",
    "        fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_gaze_yaw'], mode='markers', name='delta_gaze_yaw'))\n",
    "    elif attribute == 'hp':\n",
    "        fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_hp_pitch'], mode='markers', name='delta_hp_pitch'))\n",
    "        fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_hp_roll'], mode='markers', name='delta_hp_roll'))\n",
    "        fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_hp_yaw'], mode='markers', name='delta_hp_yaw'))\n",
    "        \n",
    "    emo = 0\n",
    "    for i in video_df['frame_num']:\n",
    "        _emo = video_df[video_df['frame_num'] == i]['emotion'].values[0]\n",
    "        if emo != _emo:\n",
    "            # write vertical line\n",
    "            if _emo == 0:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-90, 90], mode='lines', line=dict(color='blue', width=1, dash='dash'), showlegend=False))\n",
    "            elif _emo == 1:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-90, 90], mode='lines', line=dict(color='red', width=1, dash='dash'), showlegend=False))\n",
    "            elif _emo == 2:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-90, 90], mode='lines', line=dict(color='green', width=1, dash='dash'), showlegend=False))\n",
    "        emo = _emo\n",
    "           \n",
    "    # bold x axis\n",
    "    fig.add_trace(go.Scatter(x=[0, video_df['frame_num'].max()], y=[0, 0], mode='lines', line=dict(color='black', width=2, dash='dash'), showlegend=False))\n",
    "    fig.update_yaxes(range=[-90, 90], title_text='degree')\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=30, b=0),\n",
    "        legend=dict(orientation='h')\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    return video_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eyeball_move_and_hp(video_name, range=90):\n",
    "    df = pd.read_csv('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/emo_and_au-gaze-hp(video1-25).csv')\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    df['video_name'], df['frame_num'] = zip(*df['img_path'].map(util.get_video_name_and_frame_num))\n",
    "    video_df = df[df['video_name'] == video_name]\n",
    "    video_df = video_df.reset_index(drop=True)\n",
    "    video_df = video_df.sort_values('frame_num')\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['gaze_pitch'] - video_df['hp_pitch'], mode='lines', name='eyeball_pitch'))\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['gaze_yaw'] - video_df['hp_yaw'], mode='lines', name='eyeball_yaw'))\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_pitch'], mode='lines', name='headpose_pitch'))\n",
    "    # fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_roll'], mode='lines', name='headpose_roll'))\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_yaw'], mode='lines', name='headpose_yaw'))\n",
    "    \n",
    "    emo = 0\n",
    "    for i in video_df['frame_num']:\n",
    "        _emo = video_df[video_df['frame_num'] == i]['emotion'].values[0]\n",
    "        if emo != _emo or i == 0:\n",
    "            # write vertical line\n",
    "            if _emo == 0:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-range, range], mode='lines', line=dict(color='blue', width=1, dash='dash'), showlegend=False))\n",
    "            elif _emo == 1:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-range, range], mode='lines', line=dict(color='red', width=1, dash='dash'), showlegend=False))\n",
    "            elif _emo == 2:\n",
    "                fig.add_trace(go.Scatter(x=[i]*2, y=[-range, range], mode='lines', line=dict(color='green', width=1, dash='dash'), showlegend=False))\n",
    "        emo = _emo\n",
    "        \n",
    "    # bold x axis\n",
    "    fig.add_trace(go.Scatter(x=[0, video_df['frame_num'].max()], y=[0, 0], mode='lines', line=dict(color='black', width=2, dash='dash'), showlegend=False))\n",
    "    \n",
    "    fig.update_yaxes(range=[-range, range], title_text='degree')\n",
    "    fig.update_xaxes(title_text='frame id')\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, t=30, b=0),\n",
    "        legend=dict(orientation='h')\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normarize_series(series, is_delta=False):\n",
    "    # pitch, yawの範囲を[-90,90]だと仮定し，-1~1に正規化\n",
    "    if is_delta:\n",
    "        series = series / 180\n",
    "    else:\n",
    "        series = series / 90\n",
    "    \n",
    "    # -1~1の範囲を超える値を-1~1にクリップ\n",
    "    series = series.apply(lambda x: 1 if x > 1 else x)\n",
    "    series = series.apply(lambda x: -1 if x < -1 else x)\n",
    "    \n",
    "    # 0~1に正規化\n",
    "    # series = (series + 1) / 2\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_6_graph(video_name, shift=30):\n",
    "    fig = make_subplots(rows=2, cols=3, subplot_titles=('gaze', 'eyeball', 'headpose', f'delta_gaze({shift})', f'delta_eyeball({shift})', f'delta_headpose({shift})'))\n",
    "    df = pd.read_csv('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/emo_and_au-gaze-hp(video1-25).csv')\n",
    "    \n",
    "    df['video_name'], df['frame_num'] = zip(*df['img_path'].map(util.get_video_name_and_frame_num))\n",
    "    video_df = df[df['video_name'] == video_name]\n",
    "    video_df = video_df.reset_index(drop=True)\n",
    "    video_df = video_df.sort_values('frame_num')\n",
    "    video_df['eyeball_pitch'] = video_df['gaze_pitch'] - video_df['hp_pitch']\n",
    "    video_df['eyeball_yaw'] = video_df['gaze_yaw'] - video_df['hp_yaw']\n",
    "    video_df['delta_gaze_pitch'] = [0]*len(video_df)\n",
    "    video_df['delta_gaze_yaw'] = [0]*len(video_df)\n",
    "    video_df['delta_hp_pitch'] = [0]*len(video_df)\n",
    "    video_df['delta_hp_roll'] = [0]*len(video_df)\n",
    "    video_df['delta_hp_yaw'] = [0]*len(video_df)\n",
    "    video_df['delta_eyeball_pitch'] = [0]*len(video_df)\n",
    "    video_df['delta_eyeball_yaw'] = [0]*len(video_df)\n",
    "    \n",
    "    for i in range(shift, len(video_df)):\n",
    "        video_df.loc[i, 'delta_gaze_pitch'] = video_df.loc[i, 'gaze_pitch'] - video_df.loc[i-shift, 'gaze_pitch']\n",
    "        video_df.loc[i, 'delta_gaze_yaw'] = video_df.loc[i, 'gaze_yaw'] - video_df.loc[i-shift, 'gaze_yaw']\n",
    "        video_df.loc[i, 'delta_hp_pitch'] = video_df.loc[i, 'hp_pitch'] - video_df.loc[i-shift, 'hp_pitch']\n",
    "        video_df.loc[i, 'delta_hp_roll'] = video_df.loc[i, 'hp_roll'] - video_df.loc[i-shift, 'hp_roll']\n",
    "        video_df.loc[i, 'delta_hp_yaw'] = video_df.loc[i, 'hp_yaw'] - video_df.loc[i-shift, 'hp_yaw']\n",
    "        video_df.loc[i, 'delta_eyeball_pitch'] = video_df.loc[i, 'eyeball_pitch'] - video_df.loc[i-shift, 'eyeball_pitch']\n",
    "        video_df.loc[i, 'delta_eyeball_yaw'] = video_df.loc[i, 'eyeball_yaw'] - video_df.loc[i-shift, 'eyeball_yaw']\n",
    "        \n",
    "    # normalize\n",
    "    video_df['gaze_pitch'] = normarize_series(video_df['gaze_pitch'])\n",
    "    video_df['gaze_yaw'] = normarize_series(video_df['gaze_yaw'])\n",
    "    video_df['eyeball_pitch'] = normarize_series(video_df['eyeball_pitch'])\n",
    "    video_df['eyeball_yaw'] = normarize_series(video_df['eyeball_yaw'])\n",
    "    video_df['hp_pitch'] = normarize_series(video_df['hp_pitch'])\n",
    "    video_df['hp_roll'] = normarize_series(video_df['hp_roll'])\n",
    "    video_df['hp_yaw'] = normarize_series(video_df['hp_yaw'])\n",
    "    video_df['delta_gaze_pitch'] = normarize_series(video_df['delta_gaze_pitch'], is_delta=True)\n",
    "    video_df['delta_gaze_yaw'] = normarize_series(video_df['delta_gaze_yaw'], is_delta=True)\n",
    "    video_df['delta_hp_pitch'] = normarize_series(video_df['delta_hp_pitch'], is_delta=True)\n",
    "    video_df['delta_hp_roll'] = normarize_series(video_df['delta_hp_roll'], is_delta=True)\n",
    "    video_df['delta_hp_yaw'] = normarize_series(video_df['delta_hp_yaw'], is_delta=True)\n",
    "    video_df['delta_eyeball_pitch'] = normarize_series(video_df['delta_eyeball_pitch'], is_delta=True)\n",
    "    video_df['delta_eyeball_yaw'] = normarize_series(video_df['delta_eyeball_yaw'], is_delta=True)\n",
    "    \n",
    "    \n",
    "    # (1,1) gaze\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['gaze_pitch'], mode='lines', name='gaze_pitch', legendgroup='gaze'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['gaze_yaw'], mode='lines', name='gaze_yaw', legendgroup='gaze'), row=1, col=1)\n",
    "    \n",
    "    # (1,2) eyeball_move\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['eyeball_pitch'], mode='lines', name='eyeball_pitch', legendgroup='eyeball_move'), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['eyeball_yaw'], mode='lines', name='eyeball_yaw',  legendgroup='eyeball_move'), row=1, col=2)\n",
    "    \n",
    "    # (1,3) headpose\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_pitch'], mode='lines', name='headpose_pitch', legendgroup='headpose'), row=1, col=3)\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_yaw'], mode='lines', name='headpose_yaw', legendgroup='headpose'), row=1, col=3)\n",
    "    \n",
    "    # (2,1) delta_gaze\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_gaze_pitch'], mode='markers', name='delta_gaze_pitch', legendgroup='delta_gaze', marker=dict(size=3)), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_gaze_yaw'], mode='markers', name='delta_gaze_yaw', legendgroup='delta_gaze', marker=dict(size=3)), row=2, col=1)\n",
    "    \n",
    "    # (2,2) delta_eyeball_move\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_eyeball_pitch'], mode='markers', name='delta_eyeball_pitch', legendgroup='delta_eyeball_move', marker=dict(size=3)), row=2, col=2)\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_eyeball_yaw'], mode='markers', name='delta_eyeball_yaw', legendgroup='delta_eyeball_move', marker=dict(size=3)), row=2, col=2)\n",
    "    \n",
    "    # (2,3) delta_headpose\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_hp_pitch'], mode='markers', name='delta_headpose_pitch', legendgroup='delta_headpose', marker=dict(size=3)), row=2, col=3)\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['delta_hp_yaw'], mode='markers', name='delta_headpose_yaw', legendgroup='delta_headpose', marker=dict(size=3)), row=2, col=3)\n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        for j in range(1, 4):\n",
    "            emo = 0\n",
    "            for k in video_df['frame_num']:\n",
    "                _emo = video_df[video_df['frame_num'] == k]['emotion'].values[0]\n",
    "                if emo != _emo:\n",
    "                    # write vertical line\n",
    "                    if _emo == 0:\n",
    "                        fig.add_trace(go.Scatter(x=[k]*2, y=[0, 1], mode='lines', line=dict(color='blue', width=1, dash='dash'), showlegend=False), row=i, col=j)\n",
    "                    elif _emo == 1:\n",
    "                        fig.add_trace(go.Scatter(x=[k]*2, y=[0, 1], mode='lines', line=dict(color='red', width=1, dash='dash'), showlegend=False), row=i, col=j)\n",
    "                    elif _emo == 2:\n",
    "                        fig.add_trace(go.Scatter(x=[k]*2, y=[0, 1], mode='lines', line=dict(color='green', width=1, dash='dash'), showlegend=False), row=i, col=j)\n",
    "                emo = _emo\n",
    "            \n",
    "            # bold x axis\n",
    "            fig.add_trace(go.Scatter(x=[0, video_df['frame_num'].max()], y=[0.5, 0.5], mode='lines', line=dict(color='black', width=2, dash='dash'), showlegend=False), row=i, col=j)\n",
    "            fig.update_yaxes(range=[0, 1], row=i, col=j)\n",
    "            fig.update_xaxes(title_text='frame id', row=i, col=j)\n",
    "   \n",
    "    fig.update_layout(\n",
    "        width=1500,\n",
    "        height=600,\n",
    "        margin=dict(l=0, r=0, t=30, b=0),\n",
    "        legend=dict(orientation='h')\n",
    "    ) \n",
    "    fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaze_and_hp(video_name, is_norm=False, shift=1):\n",
    "    fig = make_subplots(rows=2, cols=2, subplot_titles=('gaze', 'gaze_stat', 'headpose', 'headpose_stat'), column_widths=[0.6, 0.4])\n",
    "    df = pd.read_csv('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/emo_and_au-gaze-hp(video1-25).csv')\n",
    "    r = 90\n",
    "    \n",
    "    df['video_name'], df['frame_num'] = zip(*df['img_path'].map(util.get_video_name_and_frame_num))\n",
    "    video_df = df[df['video_name'] == video_name]\n",
    "    video_df = video_df.reset_index(drop=True)\n",
    "    video_df = video_df.sort_values('frame_num')\n",
    "    video_df['delta_gaze_pitch'] = [0]*len(video_df)\n",
    "    video_df['delta_gaze_yaw'] = [0]*len(video_df)\n",
    "    video_df['delta_hp_pitch'] = [0]*len(video_df)\n",
    "    video_df['delta_hp_roll'] = [0]*len(video_df)\n",
    "    video_df['delta_hp_yaw'] = [0]*len(video_df)\n",
    "    \n",
    "    for i in range(shift, len(video_df)):\n",
    "        video_df.loc[i, 'delta_gaze_pitch'] = video_df.loc[i, 'gaze_pitch'] - video_df.loc[i-shift, 'gaze_pitch']\n",
    "        video_df.loc[i, 'delta_gaze_yaw'] = video_df.loc[i, 'gaze_yaw'] - video_df.loc[i-shift, 'gaze_yaw']\n",
    "        video_df.loc[i, 'delta_hp_pitch'] = video_df.loc[i, 'hp_pitch'] - video_df.loc[i-shift, 'hp_pitch']\n",
    "        video_df.loc[i, 'delta_hp_roll'] = video_df.loc[i, 'hp_roll'] - video_df.loc[i-shift, 'hp_roll']\n",
    "        video_df.loc[i, 'delta_hp_yaw'] = video_df.loc[i, 'hp_yaw'] - video_df.loc[i-shift, 'hp_yaw']\n",
    "    \n",
    "    \n",
    "    if is_norm:\n",
    "        r = 1\n",
    "        video_df['gaze_pitch'] = normarize_series(video_df['gaze_pitch'])\n",
    "        video_df['gaze_yaw'] = normarize_series(video_df['gaze_yaw'])\n",
    "        video_df['hp_pitch'] = normarize_series(video_df['hp_pitch'])\n",
    "        video_df['hp_roll'] = normarize_series(video_df['hp_roll'])\n",
    "        video_df['hp_yaw'] = normarize_series(video_df['hp_yaw'])\n",
    "        \n",
    "    # (1,1) gaze\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['gaze_pitch'], mode='lines', name='gaze_pitch', legendgroup='1'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['gaze_yaw'], mode='lines', name='gaze_yaw', legendgroup='1'), row=1, col=1)\n",
    "    \n",
    "    \n",
    "    # (1,2) gaze_stat\n",
    "    # gaze_pitchとgaze_yawの平均と標準偏差をbarで表示\n",
    "    gaze_pitch_mean = video_df['gaze_pitch'].mean()\n",
    "    gaze_pitch_std = video_df['gaze_pitch'].std()\n",
    "    gaze_yaw_mean = video_df['gaze_yaw'].mean()\n",
    "    gaze_yaw_std = video_df['gaze_yaw'].std()\n",
    "    fig.add_trace(go.Bar(x=['gaze_pitch'], y=[gaze_pitch_mean], error_y=dict(type='data', array=[gaze_pitch_std]), name='gaze_pitch', showlegend=False, text=gaze_pitch_mean), row=1, col=2)\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside', row=1, col=2)\n",
    "    fig.add_trace(go.Bar(x=['gaze_yaw'], y=[gaze_yaw_mean], error_y=dict(type='data', array=[gaze_yaw_std]), name='gaze_yaw', showlegend=False, text=gaze_yaw_mean), row=1, col=2)\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside', row=1, col=2)\n",
    "    \n",
    "    # delta_gaze_pitchとdelta_gaze_yawの絶対値の平均と標準偏差をbarで表示\n",
    "    video_df['abs_delta_gaze_pitch'] = video_df['delta_gaze_pitch'].abs()\n",
    "    video_df['abs_delta_gaze_yaw'] = video_df['delta_gaze_yaw'].abs()\n",
    "    abs_delta_gaze_pitch_mean = video_df['abs_delta_gaze_pitch'].mean()\n",
    "    abs_delta_gaze_pitch_std = video_df['abs_delta_gaze_pitch'].std()\n",
    "    abs_delta_gaze_yaw_mean = video_df['abs_delta_gaze_yaw'].mean()\n",
    "    abs_delta_gaze_yaw_std = video_df['abs_delta_gaze_yaw'].std()\n",
    "    fig.add_trace(go.Bar(x=['abs_delta_gaze_pitch'], y=[abs_delta_gaze_pitch_mean], error_y=dict(type='data', array=[abs_delta_gaze_pitch_std]), name='abs_delta_gaze_pitch', showlegend=False, text=abs_delta_gaze_pitch_mean), row=1, col=2)\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside', row=1, col=2)\n",
    "    fig.add_trace(go.Bar(x=['abs_delta_gaze_yaw'], y=[abs_delta_gaze_yaw_mean], error_y=dict(type='data', array=[abs_delta_gaze_yaw_std]), name='abs_delta_gaze_yaw', showlegend=False, text=abs_delta_gaze_yaw_mean), row=1, col=2)\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside', row=1, col=2)\n",
    "\n",
    "    # (2,1) headpose\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_pitch'], mode='lines', name='headpose_pitch', legendgroup='2'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=video_df['frame_num'], y=video_df['hp_yaw'], mode='lines', name='headpose_yaw', legendgroup='2'), row=2, col=1)\n",
    "    \n",
    "    # (2,2) headpose_stat\n",
    "    # gaze_pitchとgaze_yawの平均と標準偏差を表示\n",
    "    hp_pitch_mean = video_df['hp_pitch'].mean()\n",
    "    hp_pitch_std = video_df['hp_pitch'].std()\n",
    "    hp_yaw_mean = video_df['hp_yaw'].mean()\n",
    "    hp_yaw_std = video_df['hp_yaw'].std()\n",
    "    fig.add_trace(go.Bar(x=['hp_pitch'], y=[hp_pitch_mean], error_y=dict(type='data', array=[hp_pitch_std]), name='hp_pitch', showlegend=False, text=hp_pitch_mean), row=2, col=2)\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside', row=2, col=2)\n",
    "    fig.add_trace(go.Bar(x=['hp_yaw'], y=[hp_yaw_mean], error_y=dict(type='data', array=[hp_yaw_std]), name='hp_yaw', showlegend=False, text=hp_yaw_mean), row=2, col=2)\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside', row=2, col=2)\n",
    "    \n",
    "    # delta_hp_pitchとdelta_hp_yawの絶対値の平均と標準偏差をbarで表示\n",
    "    video_df['abs_delta_hp_pitch'] = video_df['delta_hp_pitch'].abs()\n",
    "    video_df['abs_delta_hp_yaw'] = video_df['delta_hp_yaw'].abs()\n",
    "    abs_delta_hp_pitch_mean = video_df['abs_delta_hp_pitch'].mean()\n",
    "    abs_delta_hp_pitch_std = video_df['abs_delta_hp_pitch'].std()\n",
    "    abs_delta_hp_yaw_mean = video_df['abs_delta_hp_yaw'].mean()\n",
    "    abs_delta_hp_yaw_std = video_df['abs_delta_hp_yaw'].std()\n",
    "    fig.add_trace(go.Bar(x=['abs_delta_hp_pitch'], y=[abs_delta_hp_pitch_mean], error_y=dict(type='data', array=[abs_delta_hp_pitch_std]), name='abs_delta_hp_pitch', showlegend=False, text=abs_delta_hp_pitch_mean), row=2, col=2)\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside', row=2, col=2)\n",
    "    fig.add_trace(go.Bar(x=['abs_delta_hp_yaw'], y=[abs_delta_hp_yaw_mean], error_y=dict(type='data', array=[abs_delta_hp_yaw_std]), name='abs_delta_hp_yaw', showlegend=False, text=abs_delta_hp_yaw_mean), row=2, col=2)\n",
    "    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside', row=2, col=2)\n",
    "    \n",
    "    for i in range(1, 3):\n",
    "        emo = 0\n",
    "        for j in video_df['frame_num']:\n",
    "            _emo = video_df[video_df['frame_num'] == j]['emotion'].values[0]\n",
    "            if emo != _emo or j == 0:\n",
    "                # write vertical line\n",
    "                if _emo == 0:\n",
    "                    fig.add_trace(go.Scatter(x=[j]*2, y=[-r, r], mode='lines', line=dict(color='blue', width=1, dash='dash'), showlegend=False), row=i, col=1)\n",
    "                elif _emo == 1:\n",
    "                    fig.add_trace(go.Scatter(x=[j]*2, y=[-r, r], mode='lines', line=dict(color='red', width=1, dash='dash'), showlegend=False), row=i, col=1)\n",
    "                elif _emo == 2:\n",
    "                    fig.add_trace(go.Scatter(x=[j]*2, y=[-r, r], mode='lines', line=dict(color='green', width=1, dash='dash'), showlegend=False), row=i, col=1)\n",
    "            emo = _emo\n",
    "            \n",
    "        # bold x axis\n",
    "        fig.add_trace(go.Scatter(x=[0, video_df['frame_num'].max()], y=[0, 0], mode='lines', line=dict(color='black', width=2, dash='dash'), showlegend=False), row=i, col=1)\n",
    "        \n",
    "        fig.update_yaxes(range=[-r, r], row=i, col=1)\n",
    "        fig.update_xaxes(title_text='frame id', row=i, col=1)\n",
    "        \n",
    "        fig.update_yaxes(range=[-r, r], row=i, col=2)\n",
    "        \n",
    "    fig.update_layout(\n",
    "        width=1400,\n",
    "        height=600,\n",
    "        margin=dict(l=0, r=0, t=30, b=0),\n",
    "        legend=dict(orientation='h')\n",
    "    ) \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaze_and_hp('video25')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
