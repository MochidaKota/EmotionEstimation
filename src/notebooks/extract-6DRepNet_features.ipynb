{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.backends import cudnn\n",
    "from face_detection import RetinaFace\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from networks.sixDRepNet_networks import SixDRepNet\n",
    "from utils import sixdrepnet_util\n",
    "from utils.util import torch_fix_seed, get_video_name_list\n",
    "from dataset import HPImageList\n",
    "from preprocess import sixDRepNet_ImageTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_fix_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_dataset = HPImageList(\n",
    "    labels_path=\"/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/emo_and_au(video1-25).csv\",\n",
    "    video_name_list=get_video_name_list('/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/labels/PIMD_A/emo_and_au(video1-25)-video_name_list.csv'),\n",
    "    hp_transform=sixDRepNet_ImageTransform(phase='test')\n",
    ")\n",
    "\n",
    "hp_dataloader = DataLoader(hp_dataset, batch_size=1, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use device:cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "print(f\"use device:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#* 6DRepNet (Head Pose Estimatior)\n",
    "hp_feat_extractor = SixDRepNet(backbone_name='RepVGG-B1g2', backbone_file='', deploy=True, pretrained=False)\n",
    "hp_feat_extractor.load_state_dict(torch.load(\"/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/params/6DRepNet-snapshots/6DRepNet_300W_LP_AFLW2000.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SixDRepNet(\n",
       "  (layer0): RepVGGBlock(\n",
       "    (nonlinearity): ReLU()\n",
       "    (se): Identity()\n",
       "    (rbr_reparam): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (2): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (2): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (4): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (2): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (3): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (4): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (5): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (6): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (7): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (8): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (9): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (10): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (11): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (12): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (13): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "    (14): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (15): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (nonlinearity): ReLU()\n",
       "      (se): Identity()\n",
       "      (rbr_reparam): Conv2d(512, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (linear_reg): Linear(in_features=2048, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for params in hp_feat_extractor.parameters():\n",
    "    params.requires_grad = False\n",
    "    \n",
    "hp_feat_extractor.to(device)\n",
    "\n",
    "hp_feat_extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19931 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1403842/4270110080.py:17: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  r_matrixs += R_pred.T.reshape(1, -1).detach().cpu().numpy().tolist()\n",
      "100%|██████████| 19931/19931 [07:02<00:00, 47.18it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=len(hp_dataloader))\n",
    "\n",
    "hp_middle_features = []\n",
    "hp_logits = []\n",
    "r_matrixs = []\n",
    "hp_list = []\n",
    "img_path_list = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(hp_dataloader):\n",
    "        imgs, img_paths, _ = batch\n",
    "        imgs = imgs.to(device)\n",
    "        \n",
    "        # culc forward\n",
    "        R_pred, hp_feats, logits = hp_feat_extractor(imgs)\n",
    "        hp_middle_features += hp_feats.detach().cpu().numpy().tolist()\n",
    "        hp_logits += logits.detach().cpu().numpy().tolist()\n",
    "        r_matrixs += R_pred.T.reshape(1, -1).detach().cpu().numpy().tolist()\n",
    "        \n",
    "        euler = sixdrepnet_util.compute_euler_angles_from_rotation_matrices(R_pred)*180/np.pi\n",
    "        p_pred_deg = euler[:, 0].cpu().detach().numpy()\n",
    "        y_pred_deg = euler[:, 1].cpu().detach().numpy()\n",
    "        r_pred_deg = euler[:, 2].cpu().detach().numpy()\n",
    "        \n",
    "        # save outputs\n",
    "        img_path_list += img_paths\n",
    "        hp_list.append([p_pred_deg[0], r_pred_deg[0], y_pred_deg[0]])\n",
    "        \n",
    "        # update tqdm bar\n",
    "        pbar.update(1)\n",
    "    \n",
    "    path = '/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/interim/black.jpg'\n",
    "    black_img = cv2.imread(path)\n",
    "    black_img = sixDRepNet_ImageTransform(phase='test')(black_img)\n",
    "    black_img = black_img.to(device)\n",
    "    R_pred, hp_feats, logits = hp_feat_extractor(black_img.unsqueeze(0))\n",
    "    hp_middle_features += hp_feats.detach().cpu().numpy().tolist()\n",
    "    hp_logits += logits.detach().cpu().numpy().tolist()\n",
    "    r_matrixs += R_pred.T.reshape(1, -1).detach().cpu().numpy().tolist()\n",
    "    hp_list.append([0, 0, 0])\n",
    "    img_path_list.append(path)\n",
    "       \n",
    "# close tqdm bar\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = pd.DataFrame(img_path_list, columns=[\"img_path\"])\n",
    "df_mid_hp = pd.DataFrame(hp_middle_features, columns=[i for i in range(2048)])\n",
    "df_logits_hp = pd.DataFrame(hp_logits, columns=[i for i in range(6)])\n",
    "df_r_matrixs = pd.DataFrame(r_matrixs, columns=[i for i in range(9)])\n",
    "df_hp = pd.DataFrame(hp_list, columns=[\"pitch\", \"roll\", \"yaw\"])\n",
    "\n",
    "hp_list = pd.concat([df_path, df_hp], axis=1)\n",
    "feat_list = pd.concat([df_path, df_mid_hp], axis=1)\n",
    "logits_list = pd.concat([df_path, df_logits_hp], axis=1)\n",
    "r_matrixs_list = pd.concat([df_path, df_r_matrixs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_list.to_csv(\"/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/processed/PIMD_A/headpose.csv\")\n",
    "# feat_list.to_pickle(\"/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/processed/PIMD_A/6DRepNet_feature.pkl\")\n",
    "# logits_list.to_pickle(\"/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/processed/PIMD_A/6DRepNet_logits.pkl\")\n",
    "r_matrixs_list.to_pickle(\"/mnt/iot-qnap3/mochida/medical-care/emotionestimation/data/processed/PIMD_A/6DRepNet_r_matrixs.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
